# This is an example configuration file
# To learn more, see the full config.yaml reference: https://docs.continue.dev/reference

name: Online Ai Config
version: 1.0.0
schema: v1

# Define which models can be used
# https://docs.continue.dev/customization/models
models:
  - name: my ai
    provider: ollama
    model: qwen3:32b
    apiBase: https://85.17.65.196

# MCP Servers that Continue can access
# https://docs.continue.dev/customization/mcp-tools
mcpServers:
  - uses: anthropic/memory-mcp
